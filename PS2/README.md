# ğŸ”„ AI-Powered Intelligent Data Migration Platform

> **Track 2 Solution - DataForge Finals 2024, IIT Roorkee**

A comprehensive, AI-powered data migration platform that intelligently maps database schemas using local machine learning models, provides interactive visualizations, and ensures data integrity throughout the migration process.

---

## ğŸ¯ Problem Statement Coverage

| Requirement | Status | Implementation |
|-------------|--------|----------------|
| AI-based column matching | âœ… Complete | `semantic_matcher.py` - Local embeddings |
| Support different naming conventions | âœ… Complete | 50+ abbreviation mappings + semantic similarity |
| 1:1, 1:N, N:1 mappings | âœ… Complete | `migration_executor.py` - AdvancedMigrationExecutor |
| Data type transformations | âœ… Complete | `type_mapper.py` - TypeTransformation class |
| Validation & integrity checks | âœ… Complete | `validation_engine.py` - Comprehensive checks |
| Failed records with reasons | âœ… Complete | `migration_executor.py` - FailedRecord tracking |
| Visual representation (Sankey) | âœ… Complete | `visualization.py` - Interactive Plotly charts |
| Explainability (non-technical) | âœ… Complete | `simple_explainer.py` - Plain English explanations |
| No external API dependency | âœ… Complete | All models run locally |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STREAMLIT WEB UI (app.py)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Visualizationsâ”‚ â”‚  Mappings   â”‚ â”‚ Validations â”‚ â”‚ Execution â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         CORE MODULES                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ schema_extractor â”‚â†’â”‚ semantic_matcher  â”‚â†’â”‚  type_mapper  â”‚ â”‚
â”‚  â”‚   (DB Schema)    â”‚  â”‚ (AI Matching)     â”‚  â”‚ (Transform)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚validation_engine â”‚  â”‚  visualization   â”‚  â”‚explainability â”‚ â”‚
â”‚  â”‚  (Data Quality)  â”‚  â”‚(Sankey Diagrams) â”‚  â”‚(Why/How)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚migration_executorâ”‚  â”‚ simple_explainer â”‚                    â”‚
â”‚  â”‚(Execute + Track) â”‚  â”‚(Business Users)  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              LOCAL AI MODEL (sentence-transformers)             â”‚
â”‚              Model: all-MiniLM-L6-v2 (22M params)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd PS2
pip install -r requirements.txt
```

### 2. Create Sample Databases

```bash
python create_sample_data.py
```

### 3. Launch the Platform

```bash
streamlit run app.py
```

### 4. Open in Browser

Navigate to `http://localhost:8501`

---

## ğŸ“ Project Structure

```
PS2/
â”œâ”€â”€ app.py                      # ğŸ¨ Streamlit Web UI
â”œâ”€â”€ main.py                     # ğŸ”§ CLI Orchestrator
â”œâ”€â”€ create_sample_data.py       # ğŸ“Š Sample Database Generator
â”œâ”€â”€ requirements.txt            # ğŸ“¦ Dependencies
â”œâ”€â”€ README.md                   # ğŸ“– This file
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ schema_extractor.py     # ğŸ” Database schema extraction
â”‚   â”œâ”€â”€ semantic_matcher.py     # ğŸ§  AI-powered column matching
â”‚   â”œâ”€â”€ type_mapper.py          # ğŸ”„ Data type transformations
â”‚   â”œâ”€â”€ validation_engine.py    # âœ… Data integrity validation
â”‚   â”œâ”€â”€ visualization.py        # ğŸ“Š Sankey diagrams & charts
â”‚   â”œâ”€â”€ explainability.py       # ğŸ’¡ Technical explanations
â”‚   â”œâ”€â”€ migration_executor.py   # âš¡ Safe migration execution
â”‚   â””â”€â”€ simple_explainer.py     # ğŸ“‹ Non-technical explanations
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ source_legacy_crm.db    # ğŸ“ Source database (sample)
    â””â”€â”€ target_modern_crm.db    # ğŸ“ Target database (sample)
```

---

## ğŸ§  AI/ML Approach

### Local Embedding Model

We use **sentence-transformers** with the `all-MiniLM-L6-v2` model:
- ğŸ”’ **100% Local** - No API calls, no internet required
- âš¡ **Fast** - 22M parameters, runs on CPU
- ğŸ“ **384-dimensional** embeddings

### Matching Algorithm

```
Overall Score = (0.50 Ã— Semantic) + (0.30 Ã— Syntactic) + (0.20 Ã— Type)
```

| Component | Method | Purpose |
|-----------|--------|---------|
| **Semantic** | Cosine similarity of embeddings | Meaning-based matching |
| **Syntactic** | RapidFuzz ratio | Character-level similarity |
| **Type** | Compatibility matrix | Data type alignment |

### Abbreviation Expansion

Built-in mapping of 50+ common abbreviations:
- `cust` â†’ `customer`
- `addr` â†’ `address`
- `qty` â†’ `quantity`
- `amt` â†’ `amount`
- And many more...

---

## ğŸ¨ Features

### 1. Interactive Visualizations

- **Sankey Diagrams**: Show data flow from source to target
- **Confidence Distribution**: Histogram of match confidence scores
- **Relationship Types**: Bar chart of 1:1, 1:N, N:1 mappings
- **Complete Dashboard**: Overview of all migration metrics

### 2. Validation Engine

Pre-migration checks:
- âœ… Null value analysis
- âœ… Duplicate detection
- âœ… Orphan record detection
- âœ… Type compatibility
- âœ… Foreign key integrity

### 3. Explainability

Two modes:
- **Technical**: Detailed scores, algorithms used
- **Non-Technical**: Plain English for business users

Example non-technical explanation:
> "The column 'cust_id' from the old system will become 'customer_identifier' 
> in the new system. We're 92% confident this is correct because they both 
> represent the unique customer number."

### 4. Failed Records Tracking

Every failed record is captured with:
- Record ID
- Error type
- Error message
- Original data
- Suggested fix

---

## ğŸ“Š UI Screenshots

The Streamlit app provides 7 tabs:

1. **ğŸ“Š Visualizations** - Interactive Sankey diagrams
2. **ğŸ”— Column Mappings** - Detailed match information
3. **âœ… Validation Results** - Data quality checks
4. **ğŸ“ Migration SQL** - Generated SQL statements
5. **ğŸš€ Execute Migration** - Run migration with progress
6. **ğŸ“‹ Simple Explanations** - Business-friendly reports
7. **ğŸ“„ Report** - Full technical documentation

---

## ğŸ”§ Configuration

### Matching Threshold

Adjust in the sidebar (default: 0.4):
- **Higher** (0.7+): Only very confident matches
- **Lower** (0.3): More matches, may need review

### Batch Size

For migration execution (default: 100):
- Smaller batches = Better error tracking
- Larger batches = Faster migration

---

## ğŸ§ª Testing

Run the sample workflow:

```bash
# Create sample databases
python create_sample_data.py

# Run CLI analysis
python main.py

# Or launch the web UI
streamlit run app.py
```

---

## ğŸ“ˆ Sample Databases

The sample data simulates a CRM migration:

### Source (Legacy CRM)
- `customers` table with abbreviations (`cust_id`, `fname`, `lname`)
- `orders` table with legacy naming
- `order_items` with old conventions

### Target (Modern CRM)
- `customers` with full names (`customer_id`, `first_name`)
- `orders` with modern naming
- `order_items` with new conventions

---

## ğŸ† Judging Criteria Alignment

| Criteria | Our Solution |
|----------|--------------|
| **Innovation** | Local AI embeddings without external APIs |
| **Technical Complexity** | Multi-signal matching, batch migration |
| **Completeness** | All PS2 requirements covered |
| **UI/UX** | Modern Streamlit interface with 7 tabs |
| **Explainability** | Dual-mode (technical + business) |
| **Visualization** | Interactive Plotly Sankey diagrams |

---

## ğŸ‘¥ Team

**DataForge Finals 2024 - IIT Roorkee**

---

## ğŸ“ License

MIT License - Built for DataForge Finals 2024
